export const messagesEn = {
  // General
  "common.scroll": "Scroll",
  "common.available": "Available for new projects",
  "common.contactMe": "Contact me",
  "common.viewProjects": "View my projects",
  "common.discover": "Discover â†’",
  "common.sendMessage": "Send message",
  "common.name": "Name",
  "common.email": "Email",
  "common.message": "Message",
  "common.sending": "Sending...",
  "common.contactInfo": "Contact Information",
  "common.professionalLinks": "Professional Links",
  "common.downloadCv": "Download my resume",
  "common.githubProfile": "GitHub Profile",
  "common.linkedinProfile": "LinkedIn Profile",
  "common.location": "Location",
  "common.languages": "Languages",

  // Hero
  "hero.title": "Mustapha",
  "hero.subtitle": "Software Architect",
  "hero.description.part1": "Passionate about full-stack development and artificial intelligence.",
  "hero.description.part2": "I turn complex ideas into ",
  "hero.description.highlight": "innovative products",

  // Resume header
  "resume.title": "Software Architect",
  "resume.location": "Toulouse, Occitanie, France",

  // About
  "about.title": "About me",
  "about.presentation": "Presentation",
  "about.presentation.p1": "Software engineer passionate about full-stack development and AI. I combine technical expertise and product vision to build impactful, innovative solutions.",
  "about.presentation.p2": "I constantly experiment with emerging technologies (RAG, blockchain, NLP) and transform complex ideas into real products, from design to large-scale deployment.",
  "about.location": "Location",
  "about.location.value": "Toulouse, Occitanie, France",
  "about.languages": "Languages",
  "about.languages.items": "ðŸ‡«ðŸ‡· French (Native);ðŸ‡¦ðŸ‡ª Arabic (Native);ðŸ‡ªðŸ‡¸ Spanish (Native);ðŸ‡ªðŸ‡¸ Catalan (Native);ðŸ‡¬ðŸ‡§ English (Fluent);ðŸ‡®ðŸ‡¹ Italian (Conv.)",
  "about.education": "Education",
  "about.education.items": "â€¢ Master Software Architect - EPITECH;â€¢ Bachelor DevOps - EPSI (Honors);â€¢ Web Developer - SIMPLON",

  // Contact
  "contact.title": "Contact Me",
  "contact.alert": "Message sent! (Feature to implement)",
  "contact.success": "Message sent successfully! I'll get back to you soon.",
  "contact.error": "Failed to send message. Please try again or contact me directly.",
  "contact.footer": "Â© 2025 Mustapha El Hachmi Mahti. All rights reserved.",

  // Sections
  "sections.experiences": "Professional Experience",
  "sections.projects": "Projects",
  "sections.skills": "Skills",

  // Labels
  "labels.stack": "Stack",

  // How It's Made Modal
  "howItsMade.title": "How This Portfolio Was Made",
  "howItsMade.subtitle": "Behind the scenes of this interactive portfolio",
  "howItsMade.overview.title": "Overview",
  "howItsMade.overview.description": "This portfolio was built from scratch using modern web technologies to create a smooth, interactive experience. Every animation, transition, and interaction was carefully crafted to showcase both technical skills and attention to detail.",
  "howItsMade.techStack.title": "Tech Stack",
  "howItsMade.techStack.items": "Next.js 15 - React framework with App Router and Server Components;TypeScript - Type-safe development across the entire codebase;Tailwind CSS - Utility-first CSS framework for rapid styling;Framer Motion - Production-ready animation library for React;GSAP & ScrollTrigger - Advanced scroll-based animations and parallax effects;Lenis - Smooth scroll library for enhanced scrolling experience;React Hook Form - Performant form handling with validation;i18n - Internationalization support for English and French",
  "howItsMade.animations.title": "Animation Techniques",
  "howItsMade.animations.items": "Scroll-triggered animations using GSAP ScrollTrigger for dynamic content reveal;Parallax effects on hero section and project titles for depth perception;Stagger animations on project cards for sequential appearance;3D tilt effects on project cards using custom TiltCard component;Smooth page transitions with Framer Motion variants;Micro-interactions on buttons and links with hover/tap states;Floating badge animation in hero section with continuous motion;Timeline-based animations for experience cards;Magnetic cursor effects on interactive elements",
  "howItsMade.features.title": "Key Features",
  "howItsMade.features.items": "Fully responsive design that works seamlessly on mobile, tablet, and desktop;Dark-themed UI with glassmorphism effects and subtle gradients;Bilingual support with instant language switching (EN/FR);Dynamic project pages with detailed case studies;Smooth scroll with Lenis for enhanced user experience;Optimized performance with Next.js Image component and lazy loading;SEO-friendly with proper meta tags and Open Graph protocol;Accessible UI with proper ARIA labels and keyboard navigation;Type-safe routing with Next.js App Router;Component-based architecture for maintainability",
  "howItsMade.performance.title": "Performance & Optimization",
  "howItsMade.performance.description": "Built with performance in mind, this portfolio uses Next.js server components for fast initial page loads, code splitting for optimal bundle sizes, and optimized images with automatic lazy loading. Animations are GPU-accelerated using transform and opacity properties to maintain 60fps.",
  "howItsMade.viewSource": "View Source Code on GitHub",

  // Experiences (EN)
  "exp.actual.title": "Full Stack Developer",
  "exp.actual.company": "Groupe Actual",
  "exp.actual.location": "Toulouse",
  "exp.actual.period": "September 2022 â€” September 2025",
  "exp.actual.points": "Web Development: Designed and built complex React/TypeScript apps (50,000+ users) with advanced UIs and optimized state management;Mobile Applications: Cross-platform iOS/Android with React Native/Expo (250,000+ downloads);Backend Architecture: Designed NestJS microservices with RESTful APIs, PostgreSQL/Redis data layers;Performance & Scalability: +30% performance gains, caching and real-time monitoring;Data Engineering: BigQuery integration for business analytics and highly available data pipelines",
  "exp.actual.stack": "React, TypeScript, React Native, NestJS (NodeJS), MySQL, Redis, GCP",

  "exp.bizness.title": "Full Stack Developer",
  "exp.bizness.company": "Groupe Bizness",
  "exp.bizness.location": "Toulouse",
  "exp.bizness.period": "January 2022 â€” August 2022",
  "exp.bizness.points": "Microservices Architecture: Event-driven design with multi-source aggregation APIs;Real-time Apps: WebSockets and Server-Sent Events for collaborative interfaces;Database & APIs: APIs built with SAP HANA backend",
  "exp.bizness.stack": "Node.js, WebSockets, SAP HANA",

  "exp.jump.title": "Full Stack Developer",
  "exp.jump.company": "SociÃ©tÃ© JUMP",
  "exp.jump.location": "Toulouse",
  "exp.jump.period": "May 2021 â€” July 2021",
  "exp.jump.points": "E2E test automation with Selenium WebDriver, Cucumber JS and Gherkin;Custom Slack commands with Bolt JS and NestJS;Automated workflows to boost team productivity",
  "exp.jump.stack": "Selenium, Cucumber JS, Bolt JS, NestJS",

  "exp.syntrix.title": "Co-founder & CTO",
  "exp.syntrix.company": "Syntrix - Compliance & Anti-Fraud Platform",
  "exp.syntrix.location": "Remote",
  "exp.syntrix.period": "July 2023",
  "exp.syntrix.points": "SaaS compliance platform (3 enterprise clients). Clients: Al Fardan Exchange and law firms.;Backend Microservices: NestJS modules (FATCA/CRS) and CoreBanking integration;Web Apps: NextJS (React) interface for automated KYC portal and compliance tools;Real-time Systems: Anti-fraud module with incident detection and automated alerting",
  "exp.syntrix.stack": "React (NextJS), NestJS (NodeJS), PostgreSQL, Redis, Kubernetes, Rabbitmq",

  // Projects
  "project.chat.title": "Real-Time Chat Application",
  "project.chat.description": "Production-ready full-stack chat platform with Google OAuth, direct messaging, group chats, and real-time media sharing.",
  "project.chat.category": "Full-Stack / Real-Time",
  "project.chat.impact": "Monorepo with 100+ files, 95% TypeScript",
  "project.chat.fullDescription": "A sophisticated enterprise-grade messaging platform built with modern technologies, featuring Google OAuth authentication, direct messaging, group chats with up to 50 members, and real-time media sharing capabilities. The application employs a monorepo architecture with TypeScript throughout (95% of codebase), ensuring complete type safety across the entire stack. Deployed with Docker containerization and Ansible automation for production-ready infrastructure.",
  "project.chat.features": "Google OAuth 2.0 authentication with secure JWT token management and refresh tokens;Real-time bidirectional messaging via WebSockets with Socket.IO and automatic reconnection;Group chats supporting up to 50 concurrent members with role-based permissions;Media sharing with drag-and-drop support (images, GIFs) and presigned URL generation;Typing indicators showing active typists in real-time with debouncing;Message read receipts and delivery status tracking across multiple users;Online/offline status tracking with presence system and last seen timestamps;Infinite scroll for message history with cursor-based pagination;Optimistic UI updates for instant feedback and responsive user experience;Full-screen media viewer with keyboard navigation and touch gestures;Mobile-first responsive design with Tailwind CSS and shadcn/ui components;User search and discovery with real-time filtering;Profile management (bio, website, avatar) with image optimization;Message pagination for performance optimization on large conversations;Real-time notifications for new messages and mentions",
  "project.chat.challenges": "Custom WebSocket JWT authentication adapter - Built secure middleware for verifying JWT tokens on WebSocket handshake, enabling authentication for real-time connections;Cursor-based pagination strategy - Implemented efficient message history loading using database cursors instead of offset pagination, improving performance by 70% on large datasets;Scalable media storage architecture - Designed and integrated Cloudflare R2 (S3-compatible) with presigned URLs for secure, scalable media delivery without server bottleneck;Real-time state synchronization - Solved complex problem of keeping message state consistent across multiple connected clients using Socket.IO rooms and event broadcasting;Room-based message routing - Developed automatic user subscription system to personal and group rooms on connection for targeted message delivery without overhead;Multi-user read receipt tracking - Implemented efficient read receipt system tracking individual read status for each user in group chats without N+1 query problems;WebSocket connection management - Built robust reconnection logic with exponential backoff and state recovery after network interruptions;Database schema optimization - Designed Prisma models with strategic indexing on frequently queried fields (email, username, roomId, createdAt) for sub-50ms query times",

  "project.syntrix.title": "Syntrix - Legal Services Platform",
  "project.syntrix.description": "Modern full-stack platform for law firms featuring client management, secure document handling, and planned KYC verification system for regulatory compliance.",
  "project.syntrix.category": "Full-Stack / Legal Tech",
  "project.syntrix.impact": "Monorepo architecture with 72.8% TypeScript coverage",
  "project.syntrix.fullDescription": "An enterprise-grade legal services platform designed for law firms and independent attorneys to digitalize their practice. Built with a modern monorepo architecture using Yarn Workspaces, the platform features a NestJS backend API and Next.js frontend with React 19. The application is containerized with Docker and includes comprehensive testing, code quality tools, and follows industry best practices. Designed with security and compliance in mind, with planned KYC/AML verification capabilities to meet legal industry regulatory requirements.",
  "project.syntrix.features": "Modern monorepo architecture with Yarn Workspaces for efficient code sharing and dependency management;Next.js 15 frontend with App Router, Server Components, and React 19 for optimal performance;NestJS 11 backend with modular architecture, dependency injection, and TypeScript type safety;Responsive mobile-first design with Tailwind CSS 4 for seamless experience across all devices;Docker Compose configuration for consistent development and production environments;Interactive CLI menu for easy project startup and environment selection;Automated code formatting with Prettier across the entire codebase;Comprehensive ESLint configuration with TypeScript-specific rules and recommended practices;Jest testing infrastructure for unit tests, E2E tests, and code coverage reporting;Hot reload and fast refresh for instant feedback during development;Next.js Image optimization with automatic lazy loading and responsive images;Environment variable management with validation and type safety;Production-ready deployment configuration for Vercel and AWS;Geist font family integration for modern, professional typography;Code splitting and tree shaking for optimal bundle sizes",
  "project.syntrix.challenges": "Monorepo configuration - Architected scalable Yarn Workspaces setup managing multiple applications (front/back) with shared dependencies, reducing bundle size by 40% through package deduplication;TypeScript strict mode across stack - Enforced strict type checking throughout 72.8% TypeScript codebase, eliminating runtime type errors and improving IDE intellisense;Docker multi-service orchestration - Designed Docker Compose configuration managing frontend, backend, and database services with proper networking, volume persistence, and health checks;Development workflow optimization - Built custom interactive CLI tool with Inquirer for streamlined project startup, reducing context switching and improving developer experience;Next.js 15 App Router migration - Successfully implemented new App Router architecture with server and client components, optimizing initial page load by 50%;Code quality automation - Integrated ESLint with TypeScript parser and Prettier for automated formatting, enforcing consistent code style across team contributions;Testing strategy implementation - Established comprehensive testing infrastructure with Jest supporting unit tests, integration tests, and E2E testing with coverage reporting;Build optimization - Configured SWC compiler for faster builds (20x faster than Babel) and optimized production bundles with tree shaking",
  "project.syntrix.plannedFeatures": "KYC/AML Module - Complete Know Your Customer verification system with document upload, OCR verification, identity validation, and compliance screening for regulatory requirements;Client Portal - Secure dashboard for clients to view case status, upload documents, and communicate with attorneys;Document Management System - Centralized secure storage with version control, access permissions, and audit trail for legal documents;Appointment Scheduling - Calendar integration with automated reminders and conflict detection for client meetings;Billing & Invoicing - Time tracking, expense management, and automated invoice generation with payment processing;Case Management - Comprehensive system for tracking cases, deadlines, hearings, and associated documents with workflow automation;Secure Messaging - End-to-end encrypted communication between attorneys and clients with read receipts and file sharing;Role-Based Access Control - Granular permission system for partners, associates, paralegals, and clients;AML Screening Integration - Automated screening against international sanctions lists and PEP databases;GDPR/Privacy Compliance - Data protection features including data export, deletion, consent management, and audit logs;Multi-language Support - Internationalization for serving clients in multiple jurisdictions;Analytics Dashboard - Business intelligence with case statistics, revenue tracking, and performance metrics",

  "project.coverLetter.title": "AI-Powered Cover Letter Generator - Chrome Extension",
  "project.coverLetter.description": "Intelligent Chrome extension that automatically generates personalized cover letters by analyzing job postings in real-time and matching them with user resumes using advanced AI technology.",
  "project.coverLetter.category": "Full-Stack / Browser Extension / AI",
  "project.coverLetter.impact": "Monorepo with 92.8% TypeScript - Production browser extension",
  "project.coverLetter.fullDescription": "A sophisticated AI-powered Chrome extension that revolutionizes the job application process by automatically generating tailored cover letters. The extension intelligently scrapes job posting content from any careers page, analyzes the requirements using AI, and creates personalized cover letters that align perfectly with the candidate's resume. Built with a monorepo architecture featuring a React-based Chrome extension frontend and a robust NestJS backend API, the application leverages DeepSeek AI for natural language processing and supports multi-language generation, matching the job posting's language automatically.",
  "project.coverLetter.features": "Real-time job posting extraction from any career website using content scripts and DOM manipulation;Intelligent HTML parsing to extract job title, company, description, requirements, and qualifications;AI-powered cover letter generation using DeepSeek LLM with customizable prompts and instructions;Automatic language detection and matching - generates cover letters in the same language as job posting;Google OAuth 2.0 authentication with secure JWT token management and refresh token rotation;Resume upload and OCR processing with Tesseract.js for extracting text from PDF documents;PDF parsing capabilities to read existing resume documents and extract structured content;Custom instruction system allowing users to emphasize specific skills or adjust tone/length;One-click copy to clipboard functionality for instant application submission;PDF export feature to download generated cover letters in professional format;Chrome extension popup interface with modern glassmorphic design and gradient backgrounds;Local storage caching for last generated letter to prevent unnecessary API calls;Tab-based navigation (Generate, Profile, Settings) with smooth transitions;Status messages and loading states with real-time progress indicators;Resume content storage and management in PostgreSQL database with Prisma;RESTful API backend with proper validation using class-validator and class-transformer;Docker containerization for consistent development and production environments;Axios interceptors for automatic authentication token injection and error handling;Chrome extension permissions for tabs, storage, scripting, and active tab access;Background script for persistent job details extraction across tabs",
  "project.coverLetter.challenges": "Cross-origin content scraping - Implemented Chrome extension content scripts with proper permissions (host_permissions for https://*/*) to inject scripts into job posting pages and extract structured data from diverse HTML layouts across different career platforms;Dynamic website parsing - Built robust DOM traversal algorithms to handle varying HTML structures from different companies (LinkedIn, Indeed, Greenhouse, Lever, etc.), using multiple fallback selectors to ensure reliable job details extraction;AI prompt engineering - Crafted sophisticated multi-part prompts that analyze both raw HTML and extracted text content (up to 120K characters), instructing DeepSeek AI to generate authentic cover letters without inventing experience, maintaining 250-350 word length constraints;Resume OCR accuracy - Integrated Tesseract.js for optical character recognition on scanned PDF resumes, implementing preprocessing techniques to improve text extraction accuracy from various document formats and layouts;Chrome extension authentication flow - Solved complex authentication challenge by implementing secure JWT token storage in chrome.storage.local, with automatic token refresh before API calls and seamless Google OAuth redirect handling;PDF generation in browser - Implemented client-side PDF creation using jsPDF library, formatting cover letter content with proper margins, fonts, and professional styling without backend dependency;Extension state management - Designed React hooks pattern (useCoverLetterGenerator, useAuth, useApi) for managing complex asynchronous workflows including tab querying, message passing, and API calls within Chrome extension context;Language detection and matching - Implemented intelligent language analysis in AI prompt to ensure cover letter language matches job posting, handling edge cases with mixed-language content and maintaining professional tone across languages;API error handling and retry logic - Built comprehensive error handling with user-friendly status messages, automatic retry for failed requests, and graceful degradation when resume is missing;Monorepo architecture coordination - Configured Yarn Workspaces to manage shared types and dependencies between extension and backend, ensuring type safety across the full stack with consistent TypeScript configurations",
  "project.coverLetter.architecture": "Chrome Extension (Plasmo) - React-based popup UI with TypeScript, content scripts for DOM scraping, and background service worker;Backend API (NestJS) - Modular architecture with Controllers, Services, and DTOs for cover letter generation and document management;Database Layer (Prisma + PostgreSQL) - ORM for user profiles, resume storage, and authentication token management;AI Integration - DeepSeek API client with custom prompts, temperature tuning (0.7), and max token limits (1000) for optimal generation;Authentication System - Google OAuth 2.0 with Passport strategies, JWT token generation, and refresh token rotation;Docker Setup - Multi-container orchestration with Docker Compose for backend, database, and development environment",
  "project.coverLetter.technicalHighlights": "Content Script Injection - Dynamic script execution via chrome.scripting.executeScript() for isolated job details extraction;Message Passing Protocol - Chrome extension messaging between popup, content scripts, and background worker for cross-context communication;Type-Safe APIs - Full TypeScript coverage (92.8%) with shared interfaces between extension and backend for JobDetails, User, and API responses;Validation Pipeline - Class-validator decorators on DTOs (GenerateCoverLetterDto) ensuring data integrity before AI processing;Secure Storage - Chrome local storage for caching with encryption considerations for sensitive authentication tokens;Axios Instance Pattern - Centralized API service class with request/response interceptors for authentication and error handling;React Hooks Pattern - Custom hooks for authentication (useAuth), data fetching (useApi), and business logic (useCoverLetterGenerator);PDF Processing Pipeline - Multi-step document handling: upload â†’ OCR (Tesseract) â†’ text extraction (pdf-parse) â†’ storage (Prisma)",
  "project.coverLetter.userFlow": "User installs Chrome extension and authenticates via Google OAuth;User uploads resume (PDF) which is processed via OCR and stored in database;User navigates to any job posting page (LinkedIn, Indeed, company website);User opens extension popup and optionally enters custom instructions;User clicks 'Generate Cover Letter' triggering job details extraction from current tab;Extension sends job HTML, extracted text, and user resume to backend API;DeepSeek AI analyzes job requirements and generates personalized cover letter;Generated letter appears in popup with copy and PDF download options;User can regenerate with different instructions or save for later use",

  "project.rlSuite.title": "Reinforcement Learning Suite - Multi-Environment AI Agent",
  "project.rlSuite.description": "Comprehensive reinforcement learning project implementing Q-Learning, SARSA, and Deep Q-Network (DQN) algorithms across multiple game environments including classic Gymnasium and Atari games.",
  "project.rlSuite.category": "AI/ML / Reinforcement Learning",
  "project.rlSuite.impact": "100% Python - Academic research project for Epitech MSc Pro",
  "project.rlSuite.fullDescription": "An advanced artificial intelligence project exploring multiple reinforcement learning algorithms applied to various game environments. The project demonstrates mastery of fundamental RL concepts (Q-Learning, SARSA) on classic Gymnasium environments, and extends to cutting-edge deep reinforcement learning with DQN implementation for Atari Pong. Built as part of the Epitech Master's program (T-AIA-902), this suite showcases the complete pipeline from algorithm implementation to model training, evaluation, and deployment with pre-trained models.",
  "project.rlSuite.features": "Q-Learning implementation for Frozen Lake 8x8 environment with configurable slipperiness;SARSA (State-Action-Reward-State-Action) algorithm for on-policy learning;Deep Q-Network (DQN) with experience replay and target network for Atari Pong;Cliff Walking environment with both Q-Learning and SARSA implementations for comparison;Taxi Driver environment with optimized Q-Learning for complex navigation;Model persistence with pickle (.pkl) and PyTorch (.pt) formats for reusability;Interactive play mode to test trained agents in real-time with human-readable rendering;TensorBoard integration for training visualization and performance metrics tracking;GPU acceleration with CUDA for faster DQN training on complex environments;Epsilon-greedy exploration strategy with decay for optimal exploitation-exploration balance;Modular codebase with separate training and testing scripts for each environment;Comprehensive documentation with detailed PDF report and presentation slides;Visual rendering with Pygame for human observation of agent behavior;Configurable hyperparameters (learning rate, discount factor, epsilon decay);Pre-trained models included for immediate testing and demonstration",
  "project.rlSuite.challenges": "Q-Table convergence optimization - Tuned learning rate (alpha) and discount factor (gamma) to achieve 95%+ success rate on Frozen Lake, balancing exploration vs exploitation with epsilon-greedy decay strategy;Credit assignment problem in sparse rewards - Implemented efficient Q-value updates for Cliff Walking where rewards only appear at goal state, using temporal difference learning to propagate value backwards;DQN stability and convergence - Solved notorious instability issues in deep RL by implementing experience replay buffer (storing 10K+ transitions) and separate target network updated every N episodes to break correlation in training data;High-dimensional state space handling - Designed convolutional neural network architecture for Atari Pong to process 84x84 pixel frames, using frame stacking (4 consecutive frames) to capture motion and velocity information;Catastrophic forgetting in neural networks - Mitigated through experience replay mechanism that samples random mini-batches from memory, preventing the network from forgetting previously learned strategies;Training time optimization - Leveraged CUDA GPU acceleration and parallel environment processing to reduce DQN training time from 40+ hours to under 8 hours on complex Atari games;Environment stochasticity - Handled non-deterministic Frozen Lake transitions (is_slippery mode) by training for longer episodes and averaging Q-values to learn robust policies;Reward shaping for faster learning - Analyzed and tuned reward structures in Taxi Driver to incentivize efficient passenger pickup/drop-off while penalizing unnecessary movements",
  "project.rlSuite.algorithms": "Q-Learning (Off-Policy TD Control) - Model-free algorithm learning optimal action-value function independently of agent's current policy;SARSA (On-Policy TD Control) - Updates Q-values based on action actually taken by current policy, more conservative than Q-Learning;Deep Q-Network (DQN) - Combines Q-Learning with deep neural networks for handling high-dimensional visual inputs from raw pixels;Experience Replay - Stores transitions in replay buffer and samples random mini-batches to break temporal correlations;Target Network - Separate network for generating Q-value targets, updated periodically to stabilize training;Epsilon-Greedy Exploration - Balances random exploration with greedy exploitation, with exponential decay schedule",
  "project.rlSuite.environments": "Frozen Lake 8x8 - Navigate icy grid world avoiding holes to reach goal, with optional stochastic transitions;Cliff Walking - Walk along cliff edge to reach goal while avoiding falling off (high negative reward);Taxi Driver - Multi-objective task: navigate grid, pick up passenger, drop at destination efficiently;Atari Pong - Classic arcade game requiring visual processing and temporal reasoning to beat opponent",

  "project.voiceTrain.title": "Voice-Controlled Train Route Finder with NER & Graph Database",
  "project.voiceTrain.description": "Advanced AI system combining speech recognition, Named Entity Recognition (NER), and graph database algorithms to find optimal train routes through natural language voice commands.",
  "project.voiceTrain.category": "AI/ML / NLP / Graph Database",
  "project.voiceTrain.impact": "90.8% Jupyter Notebooks - Academic AI research project",
  "project.voiceTrain.fullDescription": "A sophisticated artificial intelligence system that revolutionizes train travel planning through natural voice interaction. Users can simply speak their travel requests in French (e.g., 'Je veux aller de Toulouse Ã  Paris en passant par Lyon'), and the system uses advanced NLP techniques to extract departure/arrival locations and intermediate stops, then calculates the optimal route using Neo4j's graph algorithms. The project combines three major AI components: Speech-to-Text (STT) with Vosk, Named Entity Recognition using both BERT and spaCy models, and graph-based pathfinding with Neo4j, demonstrating end-to-end AI pipeline development from data collection to production deployment.",
  "project.voiceTrain.features": "Voice-to-text recognition with Google Speech Recognition and offline Vosk model (French);Multiple NER approaches: BERT-based custom model and spaCy fine-tuned models;Named Entity Recognition for extracting departure, arrival, and transit locations from natural language;Custom BERT classifier trained on 20,000+ synthetic French transportation phrases;Three spaCy model variants: base, transit-aware, and large language models;Neo4j graph database with 817 station nodes and 1,574 route relationships;Dijkstra's shortest path algorithm for optimal route calculation between cities/stations;Support for multi-stop journeys with intermediate waypoints;Docker-based Neo4j deployment with automated seeding scripts;Web interface for database visualization and query exploration (Neo4j Browser);Synthetic dataset generation from templates with 20,000 unique phrases;Duplicate detection system for data quality assurance;CLI interface for flexible query options (verbose mode, path limits, algorithm selection);Comprehensive Jupyter notebooks for model training, evaluation, and experimentation;Data preprocessing pipelines for station and city information;Text normalization (hyphen, period, parenthesis handling) for entity extraction accuracy;Fallback mechanisms: voice recognition â†’ text input on failure;Multiple model selection at runtime for performance comparison;Verbose logging for debugging NER and pathfinding processes",
  "project.voiceTrain.challenges": "Custom BERT NER training - Implemented end-to-end pipeline for training BERT model on French transportation domain, including tokenization, label encoding (IOB tagging), and sequence classification with custom loss functions to handle imbalanced entity classes (departure vs arrival);Synthetic data generation at scale - Built intelligent dataset generator creating 20,000 unique French phrases from templates, ensuring no duplicates while maintaining natural language variation and realistic city/station combinations from Neo4j database;Multi-model NER architecture - Designed modular system supporting both BERT (transformer-based) and spaCy (rule-based + ML) approaches, allowing runtime model selection and performance benchmarking across different NER strategies;Neo4j graph modeling - Architected efficient graph schema with Station nodes and TRAVEL_TO relationships, including duration weights, enabling sub-second pathfinding queries across 817 stations with Dijkstra's algorithm;Speech recognition robustness - Integrated multiple STT engines (Google Cloud Speech, Vosk offline model) with graceful fallback to text input, handling French language nuances, accents, and noisy audio environments;Entity boundary detection - Solved complex problem of extracting multi-word station names (e.g., 'Gare Saint-Lazare', 'Paris Nord') from continuous speech, implementing context-aware tokenization and IOB (Inside-Outside-Beginning) tagging scheme;Docker deployment automation - Created reproducible Neo4j environment with docker-compose, automated seeding scripts, and permission management for Unix systems, ensuring consistent database state across development and production;Intermediate stop handling - Implemented multi-waypoint routing algorithm that chains multiple shortest path calculations (Aâ†’Bâ†’Câ†’D) while maintaining global optimality and avoiding cycles in the graph traversal;Text preprocessing for NER accuracy - Developed regex-based cleaning pipeline removing spaces around hyphens/periods/parentheses to match database entries exactly, improving entity linking from 60% to 95%+;Model evaluation and comparison - Established comprehensive evaluation framework in Jupyter notebooks comparing BERT vs spaCy precision/recall/F1 scores, analyzing error patterns, and identifying optimal hyperparameters through grid search",
  "project.voiceTrain.architecture": "Speech Recognition Layer - Google Speech API + Vosk offline model for French audio-to-text conversion;NER Layer - Dual approach with BERT transformer model (trained_bert_classifier.keras) and spaCy models (3 variants);Graph Database Layer - Neo4j with Cypher queries, seeded with French train station network data;Pathfinding Layer - Dijkstra's algorithm implementation via Neo4j Graph Data Science library;Data Generation Pipeline - Synthetic dataset creation with template-based phrase generation;CLI Interface - Python argparse-based command-line tool with verbose logging and configurable options",
  "project.voiceTrain.technicalComponents": "BERT Model - Fine-tuned transformer for token classification with custom entity labels (B-departure, I-departure, B-arrival, I-arrival);spaCy Models - Three trained variants: ner_transport_model_lg_final (base), ner_transport_model_lg_transit (with transit), ner_transport_model_lg (large);Neo4j Database - Graph database with Station nodes (city, name properties) and TRAVEL_TO relationships (duration property);Dataset Generator - Creates unique French phrases by replacing placeholders (#Ville1, #Ville2) with real city names;Voice Interface - PyAudio + SpeechRecognition library with microphone input and Google API integration;Shortest Path CLI - Flexible command-line tool supporting station/city names, multiple paths, and verbose output",
  "project.voiceTrain.notebooks": "BERT Training Notebooks - Model architecture design, hyperparameter tuning, loss curve visualization;spaCy Fine-tuning Notebooks - Custom entity training, model evaluation, annotation format conversion;Data Exploration Notebooks - Station network analysis, city distribution, route statistics;Model Comparison Notebooks - BERT vs spaCy performance metrics, confusion matrices, error analysis",
  "project.voiceTrain.dataFlow": "User speaks command in French â†’ Speech Recognition converts to text;Text passed to NER model (BERT or spaCy) â†’ Extracts departure, arrival, optional transit;Entities cleaned (remove spaces) â†’ Matched against Neo4j station/city names;Neo4j Cypher query executed â†’ Dijkstra's algorithm finds shortest path(s);Results returned with station sequence and total duration",
  "project.voiceTrain.usageExamples": "Voice: 'Je veux aller de Toulouse Ã  Paris' â†’ Finds shortest path between all Toulouse-Paris station pairs;Voice: 'De Toulouse Ã  Argentine en passant par Paris et Lyon' â†’ Multi-stop journey with waypoints;CLI: python shortest_neo.py Toulouse Paris -v â†’ Verbose mode with query details;CLI: python shortest_neo.py Toulouse Paris -n 2 -l 6 â†’ Returns top 2 paths per station pair, max 6 results",

  "project.jumbot.title": "Jumbot - Automated Deployment Bot for Storiz LCMS Platform",
  "project.jumbot.description": "Internal automation tool built as a Slack bot to streamline deployment processes for the Storiz Learning Content Management System, eliminating manual DevOps bottlenecks and enabling non-technical teams to deploy applications independently.",
  "project.jumbot.category": "DevOps Automation / Internal Tooling / Bot Development",
  "project.jumbot.impact": "Reduced deployment time from 1 week to minutes - Internal tool for Groupe Bizness/Actual Digital Factory",
  "project.jumbot.fullDescription": "Jumbot is a comprehensive Slack bot designed to automate the complex deployment process of the Storiz LCMS platform. Previously, non-technical sales teams had to contact developers and DevOps engineers for each client deployment, creating bottlenecks that could take up to a week. Jumbot transforms this workflow by providing an intuitive Slack interface where users can deploy, update, list, and delete Storiz environments through simple slash commands. The system handles multiple sub-applications (learniz, back-office, front-dynamic, game, back, game-scorm, learniz-scorm) with custom configurations for each client. Built with a microservices architecture using BoltJS for Slack integration, NestJS for business logic, RabbitMQ for message queuing, and MongoDB for data persistence, Jumbot demonstrates enterprise-level automation while maintaining security and auditability.",
  "project.jumbot.features": "Slack slash commands interface (/storiz-deploy-env, /storiz-list-env, /storiz-update-env, /storiz-delete-env);Dynamic modal generation with GitLab API integration for branch selection;Multi-application deployment support (7 different Storiz sub-applications);Real-time deployment status notifications with user mentions;Comprehensive audit trail with UUID tracking for all operations;GitLab branch validation and selection through API integration;MongoDB-based configuration storage with user role management;RabbitMQ message queuing for asynchronous deployment processing;Error handling with automatic failure notifications;Docker containerization with Kubernetes orchestration;Bash script execution for server-side deployment operations;User permission management and role-based access control;Environment listing with detailed configuration display;Automated deployment rollback capabilities;Integration with existing CI/CD pipelines;Cross-platform compatibility (mobile, desktop, web via Slack);Real-time chat integration for deployment coordination;Custom environment naming with regex validation (^[a-z]+$);Multi-branch deployment support for front-end and back-end repositories",
  "project.jumbot.challenges": "Complex microservices architecture design - Built distributed system with BoltJS (Slack interface), NestJS (business logic), RabbitMQ (messaging), and MongoDB (persistence), ensuring proper communication protocols (HTTP, AMQP, TCP) and maintaining high security standards between services;Slack API integration and modal development - Implemented dynamic form generation using Slack's Block Kit framework, handling user inputs, validations, and real-time updates while managing Slack's API rate limits and webhook requirements;GitLab API integration for branch management - Developed automated branch discovery and validation system, handling GitLab authentication, API pagination, and real-time branch listing for both front-end and back-end repositories;Asynchronous deployment processing - Designed robust message queuing system with RabbitMQ to handle long-running deployment operations, implementing proper error handling, timeout management, and status tracking across distributed components;Security and access control implementation - Built comprehensive user authentication and authorization system, integrating with Slack user roles, implementing UUID-based session tracking, and ensuring secure communication between all microservices;Database design for audit and configuration - Architected MongoDB schema for storing deployment configurations, user permissions, GitLab mappings, and comprehensive audit logs with efficient querying capabilities;Error handling and user feedback - Implemented sophisticated error propagation system from server-side bash scripts through RabbitMQ back to Slack, providing meaningful error messages and automated retry mechanisms;Development environment setup with ngrok - Solved local development challenges by implementing ngrok tunneling for Slack webhook testing, enabling seamless development workflow with live API integration;Bash script integration and server communication - Developed secure execution of deployment scripts on remote Fondue server, handling command injection prevention, output parsing, and real-time status reporting;CI/CD pipeline integration - Integrated Jumbot with existing GitLab CI/CD workflows, ensuring deployment consistency and maintaining compatibility with established DevOps practices",
  "project.jumbot.architecture": "Slack Interface Layer - BoltJS framework handling slash commands, modal interactions, and user notifications;API Gateway Layer - NestJS microservice managing business logic, validation, and orchestration;Message Queue Layer - RabbitMQ handling asynchronous communication between services;Database Layer - MongoDB for configuration storage and PostgreSQL for audit logs;Deployment Layer - Fondue server executing bash scripts for actual application deployment;External Integration Layer - GitLab API for branch management and Slack API for user interface",
  "project.jumbot.technicalComponents": "BoltJS Slack Bot - Custom slash commands, interactive modals, and real-time notifications;NestJS Microservice - RESTful API with TypeScript, validation pipes, and business logic;RabbitMQ Message Broker - Direct exchanges, queues, and asynchronous message processing;MongoDB Database - Document-based storage for configurations, users, and deployment history;Docker Containers - Containerized deployment with Kubernetes orchestration;GitLab CI/CD Integration - Automated pipeline triggers and branch validation",
  "project.jumbot.usageExamples": "Deploy: /storiz-deploy-env â†’ Select branches and applications â†’ Automatic deployment with notifications;List: /storiz-list-env â†’ View all deployed environments with configurations;Update: /storiz-update-env environmentname â†’ Select new applications to add/remove;Delete: /storiz-delete-env environmentname â†’ Complete environment cleanup;Help: /storiz-help-env â†’ Display comprehensive usage documentation",

  "project.myActual.title": "My Actual - Enterprise HR Platform for Temporary Workers",
  "project.myActual.description": "Comprehensive web and mobile application serving thousands of temporary workers, candidates, and agencies across France. Manages missions, contracts, documents, applications, and agency communications with real-time synchronization across platforms.",
  "project.myActual.category": "Enterprise Web/Mobile Application / HR Tech / Full-Stack Development",
  "project.myActual.impact": "Production application serving thousands of daily users across France - Groupe Actual's main platform for temporary workers",
  "project.myActual.fullDescription": "My Actual is the central digital platform for Groupe Actual, one of France's major HR and recruitment companies. This mission-critical application serves as the primary interface for temporary workers, job candidates, and agency staff to manage their professional relationships. The platform handles everything from job applications and mission management to contract processing and document storage. Built with a modern tech stack featuring React/TypeScript for web, React Native/Expo for mobile, and Laravel for backend services, the application demonstrates enterprise-scale development with high availability requirements. The system integrates with multiple data sources, provides real-time notifications, and maintains synchronization across web and mobile platforms while serving thousands of concurrent users daily.",
  "project.myActual.features": "Cross-platform availability (responsive web application and native mobile app);Mission management system for viewing current and past assignments;Job application portal with advanced search and filtering capabilities;Document management system (contracts, pay slips, certificates, attestations);Real-time notifications for important updates and required actions;Direct messaging system with agency representatives;User profile management with professional information;Mission history tracking and performance analytics;Document download and sharing capabilities;Multi-language support for diverse user base;Offline functionality for mobile users;Push notifications for mobile app users;Advanced search with Elasticsearch integration;Caching system with Redis for improved performance;Environment on Demand (EOD) system for testing new features;Automated testing pipeline with comprehensive coverage;Role-based access control for different user types;Integration with Google Cloud Platform services;Real-time data synchronization between web and mobile;Responsive design optimized for all device sizes",
  "project.myActual.challenges": "Legacy code modernization - Led migration from JSX to TSX (TypeScript) and converted class components to functional components, improving type safety and maintainability across a large codebase while maintaining backward compatibility;Cross-platform development complexity - Ensured feature parity and consistent user experience between React web application and React Native mobile app, handling platform-specific UI/UX requirements and testing across multiple devices;Enterprise-scale performance optimization - Implemented Redis caching strategies, Elasticsearch query optimization, and database indexing to maintain sub-second response times for thousands of concurrent users;Complex data relationships and business logic - Navigated intricate HR domain logic involving missions, contracts, user roles, and agency relationships while maintaining data integrity across multiple interconnected systems;Real-time synchronization challenges - Developed robust data synchronization mechanisms between web and mobile platforms, handling offline scenarios, conflict resolution, and ensuring data consistency across all user touchpoints;Testing and quality assurance - Increased test coverage for both frontend (JavaScript) and backend (PHP) components, implementing automated testing pipelines and ensuring stability for production deployments affecting thousands of users;Remote team collaboration - Adapted to fully remote work environment, mastering asynchronous communication, code review processes, and agile methodologies while maintaining high productivity and code quality standards;Bug investigation and resolution - Utilized BigQuery for complex data analysis to investigate user-reported issues, trace data inconsistencies, and identify root causes of system behaviors affecting user experience;Environment management and deployment - Worked with Kubernetes-based Environment on Demand (EOD) system for feature testing, ensuring smooth deployment pipelines and minimizing production risks;User experience optimization - Balanced technical constraints with user needs, working closely with designers and product managers to implement intuitive interfaces while maintaining system performance and reliability",
  "project.myActual.architecture": "Frontend Layer - React with TypeScript for web, React Native with Expo for mobile;Backend Layer - Laravel PHP framework with RESTful API architecture;Database Layer - PostgreSQL for relational data with Redis for caching;Search Layer - Elasticsearch for advanced search and filtering capabilities;Cloud Infrastructure - Google Cloud Platform with Kubernetes orchestration;CI/CD Pipeline - Automated testing and deployment with GitHub Actions",
  "project.myActual.technicalComponents": "React Frontend - Modern component-based architecture with TypeScript for type safety;React Native Mobile App - Cross-platform mobile development with Expo framework;Laravel Backend - PHP framework with Eloquent ORM and API resource management;PostgreSQL Database - Relational database with optimized queries and indexing;Elasticsearch Engine - Advanced search capabilities with real-time indexing;Redis Cache - In-memory data structure store for session management and caching;GCP Services - Cloud hosting, storage, and managed services integration;Kubernetes Cluster - Container orchestration for scalable deployment management",
  "project.myActual.workflowExamples": "Feature Development - Notion task assignment â†’ Local development â†’ GitHub PR â†’ Code review â†’ EOD testing â†’ Production deployment;Bug Investigation - User report â†’ BigQuery data analysis â†’ Root cause identification â†’ Fix implementation â†’ Testing â†’ Release;Mobile Testing - Expo Go app â†’ Branch-specific testing â†’ Cross-platform validation â†’ User acceptance testing;Sprint Planning - Backlog refinement â†’ Task estimation â†’ Sprint commitment â†’ Daily standups â†’ Sprint retrospective",
  "project.myActual.teamStructure": "Agile methodology with 2-week sprints and regular retrospectives;Daily standups at 9:30 AM for team synchronization;Weekly planning sessions for task prioritization and distribution;Bi-weekly backlog refinement for upcoming sprint preparation;Cross-functional collaboration with developers, designers, and product managers;Remote-first team with structured communication via Slack and Google Meet",
};


